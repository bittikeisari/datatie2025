{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d44bd9f2",
   "metadata": {},
   "source": [
    "# TampereBNB Listings - Price Prediction\n",
    "<p> Get ready for an exhilarating data science adventure! In this exciting assignment, you will dive into the world of TampereBNB, the popular platform for short-term accommodation rentals. \n",
    "    <br>\n",
    "    Your mission? To analyze data from this platform and use your data science skills to predict missing prices for some of the listings, using the tools mentioned in the following cell. </p>\n",
    "<br>\n",
    "\n",
    "## Instructions\n",
    "- Train a regression model of your choice on predicting the listing prices of the training data. \n",
    "- Use the trained model to get the price predictions for the listings in the testing data.\n",
    "- Store the resulting dataframe as a pickled (out.pkl) file. \n",
    "\n",
    "**NOTE: The code snippets for loading the data files and outputting the resulting dataframe, are provided. Do not update them.**\n",
    "\n",
    "\n",
    "#### Accessing the dataset\n",
    "To facilitate your work, we have created two separate training and testing TampereBNB csv files, located within the `data/` folder. Make sure the path to the files is the same, before submitting your solution.\n",
    "\n",
    "#### TODO\n",
    "\n",
    "- You are expected to predict prices for the listings on the testing data by using the following libraries (Besides the built-in python modules, specific libraries can be included upon request):\n",
    "    - scikit-learn (sklearn)\n",
    "    - pandas\n",
    "    - numpy\n",
    "    \n",
    "- Store your predictions as a dataframe with the attribute `Hinta` (case sensitive).\n",
    "- Save the dataframe in a pickle file, `out.pkl` (case sensitive).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827a6736-b034-4917-ba6b-307c8ee7e2e0",
   "metadata": {},
   "source": [
    "## Importing the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "id": "319c09fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.impute import SimpleImputer as Imputer\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852b0df0",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "id": "617b703b-c52a-475a-95b2-4b04a05f4fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !MAKE SURE TO NOT CHANGE THE CODE WITHIN THIS CELL!. \n",
    "# Instead, put the data files within a folder named 'data' such that the paths would work.\n",
    "training_df = pd.read_csv('./data/Tampere_BNB_training_listing.csv')\n",
    "testing_df = pd.read_csv('./data/Tampere_BNB_testing_listing.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "id": "80621696-0dd5-4484-a08b-a61939612717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Kaupunginosa           Huoneisto Talot.    m2    Rv  Krs Hissi  Kunto  \\\n",
      "0  Niemenranta       2h , kt, s, p     kt  50.0  2020  2/6    on   hyvä   \n",
      "1       Vuores            1 H + KT     kt  28.0  2018  1/4    on   hyvä   \n",
      "2  Niemenranta     3 h , kt , s, p     kt  63.0  2020  3/6    on   hyvä   \n",
      "3     Keskusta  3h+k+vh+kph/wc+...     kt  84.0  1964  5/7    on    NaN   \n",
      "4     Hervanta   2 h, kk, s, ph, p     kt  52.0  1995  6/6    on  tyyd.   \n",
      "\n",
      "   Asunnon tyyppi  Pituusaste  Leveysaste  Hinta  \n",
      "0  Kaksi huonetta   23.696606   61.524269    300  \n",
      "1           Yksiö   23.804092   61.433185    162  \n",
      "2  Kolme huonetta   23.696636   61.519368    363  \n",
      "3  Kolme huonetta   24.062369   61.463896    483  \n",
      "4  Kaksi huonetta   23.848751   61.446601    174  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1080 entries, 0 to 1079\n",
      "Data columns (total 12 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Kaupunginosa    1080 non-null   object \n",
      " 1   Huoneisto       1080 non-null   object \n",
      " 2   Talot.          1080 non-null   object \n",
      " 3   m2              1080 non-null   float64\n",
      " 4   Rv              1080 non-null   int64  \n",
      " 5   Krs             1018 non-null   object \n",
      " 6   Hissi           1080 non-null   object \n",
      " 7   Kunto           786 non-null    object \n",
      " 8   Asunnon tyyppi  1080 non-null   object \n",
      " 9   Pituusaste      1080 non-null   float64\n",
      " 10  Leveysaste      1080 non-null   float64\n",
      " 11  Hinta           1080 non-null   int64  \n",
      "dtypes: float64(3), int64(2), object(7)\n",
      "memory usage: 101.4+ KB\n"
     ]
    }
   ],
   "source": [
    "print(training_df.head())\n",
    "training_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "id": "c6bb3aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Kaupunginosa           Huoneisto Talot.     m2    Rv  Krs Hissi  Kunto  \\\n",
      "0        Kaleva  2h, k, rt, kph,...     kt   56.0  1956  3/4    on  tyyd.   \n",
      "1      Keskusta             2h,kk,s     kt   56.0  1908  NaN    on   hyvä   \n",
      "2  Hämeenpuisto  4-5 h,avok,2xkp...     kt  184.0  1928  3/6    on   hyvä   \n",
      "3      Viinikka       3h, k, kph, p     kt   65.0  1956  2/2    ei   hyvä   \n",
      "4       Leinola  4 h + k + s + w...     ok  112.0  1978  NaN    ei   hyvä   \n",
      "\n",
      "               Asunnon tyyppi  Pituusaste  Leveysaste  \n",
      "0              Kaksi huonetta   23.805462   61.496083  \n",
      "1              Kaksi huonetta   24.064453   61.468052  \n",
      "2  Neljä huonetta tai enemmän   23.751403   61.492285  \n",
      "3              Kolme huonetta   23.786301   61.489502  \n",
      "4  Neljä huonetta tai enemmän   23.914912   61.490368  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 360 entries, 0 to 359\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Kaupunginosa    360 non-null    object \n",
      " 1   Huoneisto       360 non-null    object \n",
      " 2   Talot.          360 non-null    object \n",
      " 3   m2              360 non-null    float64\n",
      " 4   Rv              360 non-null    int64  \n",
      " 5   Krs             338 non-null    object \n",
      " 6   Hissi           360 non-null    object \n",
      " 7   Kunto           259 non-null    object \n",
      " 8   Asunnon tyyppi  360 non-null    object \n",
      " 9   Pituusaste      360 non-null    float64\n",
      " 10  Leveysaste      360 non-null    float64\n",
      "dtypes: float64(3), int64(1), object(7)\n",
      "memory usage: 31.1+ KB\n"
     ]
    }
   ],
   "source": [
    "print(testing_df.head())\n",
    "testing_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276a6f7f",
   "metadata": {},
   "source": [
    "## Data Cleaning (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "id": "c3441433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the data for further processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "id": "a7655261-b358-4e1d-a746-758704421eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imputation strategy: Replace Non-existing values with the most frequent value, which is OK with at least Kunto\n",
    "cols_to_clean =['Krs','Kunto']\n",
    "\n",
    "imputer = Imputer(strategy='most_frequent')\n",
    "training_df[cols_to_clean] = imputer.fit_transform(training_df[cols_to_clean])\n",
    "training_df=training_df.dropna()\n",
    "\n",
    "testing_df[cols_to_clean] = imputer.fit_transform(testing_df[cols_to_clean])\n",
    "testing_df=testing_df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75480dc-8ad4-4fd3-bdbc-fc906926af3c",
   "metadata": {},
   "source": [
    "## Feature Engineering (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "id": "321dbb26-2549-436b-82ad-712fe41bea9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering/extraction/discovery to extract features new from the raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "id": "24aaa228",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_remove = ['Huoneisto','Kaupunginosa'] # ,'Pituusaste','Leveysaste'\n",
    "training_df = training_df.drop(cols_to_remove, axis=1)\n",
    "testing_df = testing_df.drop(cols_to_remove, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "id": "b0c637e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "taulukot = [training_df, testing_df]\n",
    "\n",
    "for x in range(len(taulukot)):\n",
    "\n",
    "    # Convert Krs to numerical values\n",
    "    y = []\n",
    "    for i in taulukot[x]['Krs']:\n",
    "        a = int(i.split('/')[0])\n",
    "        y.append(abs(a))\n",
    "\n",
    "    taulukot[x]['Krs'] = y\n",
    "    taulukot[x]['Krs'] = taulukot[x]['Krs']#.astype(int)\n",
    "\n",
    "training_df = pd.get_dummies(training_df)\n",
    "testing_df = pd.get_dummies(testing_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b9c136-891d-4b77-a45e-4466dba98153",
   "metadata": {},
   "source": [
    "## Data Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "id": "fc9144c7-d090-44e7-9ed8-82875c3e205c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement your prediction solution here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "id": "0d0e7abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = training_df.drop('Hinta', axis=1).values #returns numpy array\n",
    "# min_max_scaler = preprocessing.MinMaxScaler()\n",
    "# x_scaled = min_max_scaler.fit_transform(x)\n",
    "# xMinMax = pd.DataFrame(x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "id": "244e3ac7-f322-4dea-8def-91f03f012dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the classifiers that we will be testing\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "#train model with train data\n",
    "x = training_df.drop('Hinta', axis=1)\n",
    "clf.fit(X=x, y=training_df['Hinta'])\n",
    "   \n",
    "#predict test data\n",
    "predictions = clf.predict(X=testing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "id": "7c9c6bbf-0be4-4594-9b76-74109c7698bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure to store your predictions in the 'Hinta' attribute of the testing dataframe.\n",
    "\n",
    "# By default, the following assignment will initialize the 'Hinta' column with the given constant.\n",
    "# testing_df['Hinta'] = 1000000\n",
    "testing_df['Hinta'] = predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "id": "48a21aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([237, 309, 519, 303, 279, 387, 645, 261, 213, 276, 261, 159, 327,\n",
       "       390, 120, 192, 303, 297, 234, 195, 243, 246, 204, 264, 384, 246,\n",
       "       237, 393, 168, 321, 510, 309, 348, 318, 282, 273, 312, 282, 357,\n",
       "       351, 120, 204, 261, 180, 237, 192, 150, 354, 327, 336, 327, 168,\n",
       "       282, 234, 159, 234, 255, 207, 297, 258, 213, 114, 204, 168, 291,\n",
       "       207, 405, 195, 309, 186, 531, 225, 177, 255, 309, 192, 246, 651,\n",
       "       651, 231, 336, 144, 366, 114, 228, 168, 243, 252, 498, 246, 360,\n",
       "       168, 180, 384, 231, 177, 342, 219, 240, 192, 237, 585, 192, 327,\n",
       "       270, 390, 405, 255, 351, 222, 399, 594, 267, 150, 264, 171, 276,\n",
       "       180, 300, 285, 153, 174, 231, 363, 285, 357, 243, 192, 213, 471,\n",
       "       180, 210, 198, 168, 324, 147, 171, 237, 225, 294, 273, 315, 264,\n",
       "       120, 432, 708, 243, 213, 360, 138, 153, 177, 147, 147, 243, 183,\n",
       "       159, 426, 264, 237, 165, 132, 285, 213, 186, 342, 258, 393, 150,\n",
       "       354, 276, 234, 363, 384, 357, 303, 159, 294, 237, 315, 234, 207,\n",
       "       159, 255, 210, 366, 237, 282, 180, 213, 297, 261, 348, 231, 270,\n",
       "       267, 264, 159, 399, 594, 249, 261, 336, 351, 258, 201, 336, 381,\n",
       "       231, 366, 135, 174, 276, 159, 336,  90, 213, 387, 285, 285, 306,\n",
       "       477, 168, 897, 309, 390, 375, 594, 228, 168, 192, 282, 159, 288,\n",
       "       249, 309, 270, 420, 174, 207, 618, 327, 240, 321, 375, 180, 534,\n",
       "       177, 282, 237, 258, 267, 969, 420, 162, 387, 219, 342, 261, 177,\n",
       "       258, 201, 213, 171, 297, 153, 219, 213, 471, 255, 417, 204, 255,\n",
       "       213, 162, 216, 210, 198, 177, 168, 546, 714, 309, 285, 303, 192,\n",
       "       354, 375, 192, 114, 336, 135, 387, 210, 183, 201, 240, 255, 132,\n",
       "       417, 483, 267, 360, 204, 267, 207, 294, 315, 231, 243, 534, 225,\n",
       "       153, 660, 249, 159, 210, 243, 207, 399, 198, 192, 162, 309, 180,\n",
       "       270, 204, 360, 138, 336, 243, 177, 387, 120, 279, 210, 303, 249,\n",
       "       213, 282, 867, 120, 156, 219, 363, 213, 366, 237, 177, 261, 324,\n",
       "       126, 348, 183, 138, 513, 156, 186, 342, 270])"
      ]
     },
     "execution_count": 706,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "id": "350a1a6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([471, 471, 471, 399, 840, 492, 471, 471, 336, 471, 399, 492, 840,\n",
       "       675, 675, 399, 492, 471, 399, 336, 336, 471, 336, 471, 675, 336,\n",
       "       471, 471, 471, 675, 492, 336, 399, 399, 399, 399, 471, 471, 675,\n",
       "       399, 336, 336, 471, 471, 336, 471, 471, 471, 471, 399, 471, 471,\n",
       "       675, 399, 675, 471, 675, 336, 399, 399, 471, 336, 336, 471, 471,\n",
       "       471, 471, 471, 399, 471, 492, 336, 336, 399, 399, 471, 471, 675,\n",
       "       675, 471, 399, 675, 399, 336, 471, 399, 471, 399, 675, 399, 471,\n",
       "       675, 336, 471, 471, 336, 471, 336, 471, 471, 471, 471, 492, 399,\n",
       "       399, 675, 675, 399, 675, 336, 399, 840, 675, 471, 471, 471, 471,\n",
       "       336, 675, 399, 399, 471, 336, 675, 471, 675, 399, 471, 471, 471,\n",
       "       336, 399, 336, 471, 471, 399, 399, 336, 471, 471, 399, 399, 492,\n",
       "       336, 471, 471, 399, 336, 675, 675, 336, 471, 399, 399, 336, 336,\n",
       "       399, 840, 336, 336, 471, 471, 471, 471, 471, 675, 471, 471, 336,\n",
       "       492, 675, 399, 675, 471, 492, 471, 675, 471, 336, 399, 399, 399,\n",
       "       399, 675, 399, 399, 336, 675, 336, 336, 399, 471, 675, 471, 471,\n",
       "       471, 471, 492, 399, 840, 675, 471, 471, 399, 471, 471, 399, 492,\n",
       "       336, 675, 471, 336, 675, 675, 399, 399, 336, 492, 471, 471, 675,\n",
       "       471, 675, 471, 471, 399, 492, 840, 471, 471, 471, 675, 399, 675,\n",
       "       471, 471, 471, 675, 399, 471, 675, 471, 471, 471, 471, 336, 492,\n",
       "       471, 471, 471, 471, 471, 675, 840, 336, 492, 336, 492, 471, 336,\n",
       "       471, 471, 471, 675, 399, 399, 471, 399, 675, 471, 492, 471, 471,\n",
       "       675, 336, 336, 471, 471, 336, 471, 471, 492, 471, 471, 399, 399,\n",
       "       471, 840, 336, 471, 675, 471, 399, 336, 492, 399, 336, 399, 471,\n",
       "       492, 675, 336, 471, 399, 840, 399, 471, 492, 471, 336, 492, 471,\n",
       "       336, 399, 675, 399, 399, 336, 471, 399, 471, 336, 471, 471, 336,\n",
       "       375, 471, 492, 675, 399, 399, 471, 399, 336, 471, 471, 336, 471,\n",
       "       471, 471, 675, 336, 471, 471, 492, 399, 399, 336, 399, 471, 675,\n",
       "       336, 675, 492, 675, 675, 399, 471, 471, 492])"
      ]
     },
     "execution_count": 691,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4272e4-06c7-49b5-b7cd-977a3965ba8b",
   "metadata": {},
   "source": [
    "## Store the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "id": "06c9bac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !MAKE SURE TO NOT CHANGE THE CODE WITHIN THIS CELL!. \n",
    "testing_df.to_pickle(\"out.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d1784f-28f6-4a8e-9f93-7f381d6b7639",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "id": "e42c4025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Imputation strategy: Replace Non-existing values with the most frequent value in the union of the two dataframes\n",
    "# krs_mode = pd.concat([training_df['Krs'], testing_df['Krs']], axis=0).mode()\n",
    "# kunto_mode = pd.concat([training_df['Kunto'], testing_df['Kunto']], axis=0).mode()\n",
    "\n",
    "# # cols_to_clean =['Krs','Kunto']\n",
    "\n",
    "# imputer = Imputer(strategy='constant', fill_value=krs_mode)\n",
    "# training_df['Krs'] = imputer.fit_transform(training_df['Krs'])\n",
    "\n",
    "# imputer = Imputer(strategy='constant', fill_value=kunto_mode)\n",
    "# training_df['Kunto'] = imputer.fit_transform(training_df['Kunto'])\n",
    "\n",
    "# training_df=training_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "id": "6bb4358c-864e-410c-935d-244acc5c72a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert Kaupunginosa to numerical values\n",
    "# y = []\n",
    "# for i in training_df['']:\n",
    "#     if i == '':\n",
    "#         y.append(1)\n",
    "#     else:\n",
    "#         y.append(0)\n",
    "\n",
    "# training_df = training_df.drop('', axis=1)\n",
    "# pd.concat()\n",
    "\n",
    "# \n",
    "\n",
    "# for x in [testing_df]: # , testing_df\n",
    "\n",
    "#     # Convert Talot. to numerical values\n",
    "#     y = []\n",
    "#     for i in x['Talot.']:\n",
    "#         if i == 'ok':\n",
    "#             y.append(2)\n",
    "#         elif i == 'rt':\n",
    "#             y.append(1)\n",
    "#         else: # kt\n",
    "#             y.append(0)\n",
    "\n",
    "#     x = x.drop('Talot.', axis=1)\n",
    "#     x['Talot.'] = y\n",
    "\n",
    "#     # Convert Krs to numerical values\n",
    "#     y = []\n",
    "#     for i in x['Krs']:\n",
    "#         y.append(i.split('/')[0])\n",
    "\n",
    "#     x = x.drop('Krs', axis=1)\n",
    "#     x['Krs'] = y\n",
    "\n",
    "#     # Convert Hissi to numerical values\n",
    "#     y = []\n",
    "#     for i in x['Hissi']:\n",
    "#         if i == 'on':\n",
    "#             y.append(1)\n",
    "#         else: # ei\n",
    "#             y.append(0)\n",
    "\n",
    "#     x = x.drop('Hissi', axis=1)\n",
    "#     x['Hissi'] = y\n",
    "\n",
    "\n",
    "#     # Convert Kunto to numerical values\n",
    "#     y = []\n",
    "#     for i in x['Kunto']:\n",
    "#         if i == 'hyvä':\n",
    "#             y.append(2)\n",
    "#         elif i == 'tyyd.':\n",
    "#             y.append(1)\n",
    "#         else: # huono\n",
    "#             y.append(0)\n",
    "\n",
    "#     x = x.drop('Kunto', axis=1)\n",
    "#     x['Kunto'] = y\n",
    "\n",
    "\n",
    "#     # Convert Asunnon tyyppi to numerical values\n",
    "#     y = []\n",
    "#     for i in x['Asunnon tyyppi']:\n",
    "#         if i == 'Yksiö':\n",
    "#             y.append(1)\n",
    "#         elif i == 'Kaksi huonetta':\n",
    "#             y.append(2)\n",
    "#         elif i == 'Kolme huonetta':\n",
    "#             y.append(3)\n",
    "#         else:\n",
    "#             y.append(4)\n",
    "\n",
    "#     x = x.drop('Asunnon tyyppi', axis=1)\n",
    "#     x['Asunnon tyyppi'] = y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "joda_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
